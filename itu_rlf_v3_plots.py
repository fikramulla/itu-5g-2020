# -*- coding: utf-8 -*-
"""itu_RLF_v3_plots.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EITS0AQw6R_PYhva0F0JbofZW-gi5VDb

ITU Aclara Power Pros Team - Radio Link Failure

#####Faiz Ikramulla (fikramulla@hubbell.com ; fikramulla@aclara.com)
#####Dhruv Gaonkar (dgaonkar@hubbell.com ; dgaonkar@aclara.com)
#####Jeff Anderson (jmanderson@hubbell.com)
#####Aaron Hoock (ahoock@hubbell.com)
"""

# code starts here

import numpy as np
from numpy import array
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import io 
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn import svm
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import seaborn as sns

from google.colab import files
uploaded = files.upload()

# df2 = pd.read_csv(io.BytesIO(uploaded['turkcell_orig_1.csv']))

df2 = pd.read_csv('turkcell_orig_1.csv')

print(df2)

n = len(pd.unique(df2['rlf'])) 
n

df2.shape

(pd.unique(df2['modulation']))

len((pd.unique(df2['modulation'])))

(pd.unique(df2['capacity']))

(np.mean(df2['capacity']))

(np.mean(df2['rxlevmax']))

(np.max(df2['rxlevmax']))

(np.min(df2['rxlevmax']))

(np.std(df2['rxlevmax']))



# sort data by each modulation type - create dataframe for each type

# sample linear regresssion model for rxlevmax as x, rlf as y

# actually we are predicting T or F, so linear is not good option. will review binary classification models.

df3 = pd.get_dummies(df2, columns=['rlf'])

df3

df3.plot(x='rxlevmax', y='rlf_False', style='o')
#plt.title('Hours vs Percentage')
#plt.xlabel('Hours Studied')
#plt.ylabel('Percentage Score')
plt.show()

df3.plot(x='rxlevmax', y='rlf_True', style='o')
#plt.title('Hours vs Percentage')
#plt.xlabel('Hours Studied')
#plt.ylabel('Percentage Score')
plt.show()

df3.plot(x='bbe', y='rlf_True', style='o')

f =df3['rlf_True'].sum()
f

p = df3['rlf_False'].sum()
p

f/(f+p)*100



# subset to failed data set (611 rows) - and check for correlations

test = df3[df3["rlf_True"] >= 1]

test

#tips = sns.load_dataset("df3")
sns.relplot(x="capacity", y="rxlevmax", data=df3);

sns.relplot(x="rxlevmax", y="capacity", data=df3);

sns.relplot(x="capacity", y="rxlevmax", hue="modulation", data=df3);

df4 = pd.get_dummies(df3, columns=['card_type'])
df5 = pd.get_dummies(df4, columns=['adaptive_modulation'])
df6 = pd.get_dummies(df5, columns=['freq_band'])
df7 = pd.get_dummies(df6, columns=['modulation'])

df7

# create new df
df8 = df7.drop(['Unnamed: 0','site_id','site_no','type','datetime','scalibility_score','tip','mlid','mw_connection_no','neid','direction','polarization','link_length','severaly_error_second','error_second'], axis = 1)

# df9 = df8.drop(df8.columns[1], axis = 1, inplace = True)

list(df8.columns)

y = df8.iloc[:, 5]
y

X = df8.drop(['rlf_True','rlf_False'], axis = 1)
X

# try a SVM model (as per exammpleb)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

X_train

svc = SVC(kernel='linear', C=10.0, random_state=1)
svc.fit(X_train, y_train)

X = X_train
Y = y_train

fignum = 1

for kernel in ('linear', 'poly', 'rbf'):
    clf = svm.SVC(kernel=kernel, gamma=2)
    clf.fit(X, Y)

    # plot the line, the points, and the nearest vectors to the plane
    plt.figure(fignum, figsize=(4, 3))
    plt.clf()

    plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,
                facecolors='none', zorder=10, edgecolors='k')
    plt.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired,
                edgecolors='k')

    plt.axis('tight')
    x_min = -3
    x_max = 3
    y_min = -3
    y_max = 3

    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]
    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])

    # Put the result into a color plot
    Z = Z.reshape(XX.shape)
    plt.figure(fignum, figsize=(4, 3))
    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)
    plt.contour(XX, YY, Z, colors=['blue', 'blue', 'blue'], linestyles=['--', '-', '--'],
                levels=[-.5, 0, .5])

    plt.xlim(x_min, x_max)
    plt.ylim(y_min, y_max)

    plt.xticks(())
    plt.yticks(())
    fignum = fignum + 1
plt.show()

# prediction

pred = svc.predict(X_test)

#confusion matrix

conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)

# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')
 
plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

# metrics
print('Precision: %.3f' % precision_score(y_test, y_pred))
print('Recall: %.3f' % recall_score(y_test, y_pred))
print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))
print('F1 Score: %.3f' % f1_score(y_test, y_pred))

# ok, now we should try to get better F1 score... 
# 99.7 means no better that assuming everying thing is rlf_False (i.e. no failure) since failure rate in data set was ~0.33%.
#we should add back some weather data and distance data since that is the point of the challenge - to use weather as factor to predict.

# can also do various organization, structuing, transofrmations on the existing numerical value datab

